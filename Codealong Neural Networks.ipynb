{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code along"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hey! Welcome to the notebook. Here's some code you can play with while Chris drones on.\n",
    "\n",
    "First, imports. If you can run this next cell with no errors, you'll be just fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, LSTM, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `tensorflow` import failed but you have Theano, you might be alright."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def very_simple_network(input_1, input_2):\n",
    "    weight_1 = 1\n",
    "    weight_2 = 1\n",
    "    bias = 0\n",
    "    activation = input_1*weight_1 + input_2*weight_2 + bias\n",
    "    output = 1 if activation > 0 else 0\n",
    "    return output\n",
    "\n",
    "# Exercise: try combinations of inputs and see what the output is.\n",
    "# In particular, try combining boolean inputs.\n",
    "# What does this network represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def another_simple_network(input_1, input_2):\n",
    "    weight_1 = -2\n",
    "    weight_2 = -2\n",
    "    bias = 3\n",
    "    activation = input_1*weight_1 + input_2*weight_2 + bias\n",
    "    output = 1 if activation > 0 else 0\n",
    "    return output\n",
    "\n",
    "# Exercise: Try combinations of boolean inputs again.\n",
    "# What kind of logic gate does this network represent?\n",
    "# What is the significance of that?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# elementwise addition:\n",
    "\n",
    "vector_1 = [1,2,3,4,5]\n",
    "vector_2 = [1,2,3,4,5]\n",
    "output_vector = [2,4,6,8,10]\n",
    "\n",
    "def elementwise_add(v1,v2):\n",
    "    # Exercise. Write a function that takes vector_1\n",
    "    # and vector_2 and outputs output_vector.\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x10e753b00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDGZmVsfBYGZmdRwMZmZWx8FgZmZ1/h++ZiROBKhW5AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e6e6f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate fake dataset\n",
    "x = np.linspace(-1,1,201)\n",
    "y3 =  x**3\n",
    "plt.scatter(x, y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cubic_network = Sequential([\n",
    "    # Exercise. Define a network architecture here.\n",
    "    # Use Dense(n, input_dim=1) and play with n, then an Activation('tanh') layer\n",
    "])\n",
    "cubic_network.compile(loss='mean_squared_error', optimizer='rmsprop')\n",
    "\n",
    "# Advanced: lookup rmsprop. What is the difference between that and stochastic gradient descent?\n",
    "# More generally, why might one use an adaptive learning rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cubic_network.fit(x, y3, nb_epoch=100, # try changinge the number of epochs\n",
    "                  verbose=2)\n",
    "\n",
    "# With verbose=2, the network will output its loss after every epoch.\n",
    "# Remember we want to _minimize_ the difference between the output of\n",
    "# the network and the input data, so a small loss is a good thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y3_prime = cubic_network.predict(x)\n",
    "plt.scatter(x, y3, alpha=0.1)\n",
    "plt.plot(x, y3_prime, color='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex 5"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# I have basically copied most of this code from\n",
    "# https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py\n",
    "# Thanks be to @fchollet!\n",
    "# There are some minor stylistic changes and extra annotations (waffle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data loading\n",
    "\n",
    "def read_lines(filename):\n",
    "    '''Just a convenience function.'''\n",
    "    lines = open(filename).read().strip().split('.')\n",
    "    return lines\n",
    "\n",
    "#lines = read_lines('data/trump_speeches.txt')\n",
    "# If you prefer Shakespeare, swap out the above for this:\n",
    "lines = read_lines('data/will_play_truncated.txt')\n",
    "\n",
    "all_text = ' '.join([' '.join(x.splitlines()) for x in lines])\n",
    "\n",
    "# Chars is the full list of possible input characters.\n",
    "# We create index:character and character:index for convenience later.\n",
    "chars = sorted(list(set(all_text)))\n",
    "char_indices = {c:i for i, c in enumerate(chars)}\n",
    "indices_char = {i:c for i, c in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is a supervised learning problem. Here we create our training set of (input, output) pairs.\n",
    "\n",
    "# First define the length of the sequence\n",
    "seqlen = 40 # 40 characters at a time.\n",
    "\n",
    "# Advanced: Why do we need a fixed length? Our backend is tensorflow (or Theano),\n",
    "# which defines a fixed computation graph.\n",
    "# This has some nice features, like being able to optimize for many computing architectures\n",
    "# more easily (gpu, cpu, embedded, ...), but it means our graph is static.\n",
    "# For variable length sequences, we need the graph to be dynamic at run time.\n",
    "# Fortunately PyTorch released a couple of weeks ago, providing just this (http://pytorch.org/).\n",
    "\n",
    "# Get all ordered 40 character strings that occur in the text\n",
    "seqs = [all_text[i:i+seqlen]\n",
    "        for i in range(len(all_text)-seqlen)]\n",
    "# and the next character in all those cases\n",
    "char = [all_text[i+seqlen]\n",
    "        for i in range(len(all_text)-seqlen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vectorize (encode characters as unit vectors)\n",
    "\n",
    "# initialize empty lists of vectors with NumPy\n",
    "X = np.zeros((len(seqs),   # number of training sequences\n",
    "              seqlen,      # length of each sequence\n",
    "              len(chars)), # length of each feature vector\n",
    "             dtype=np.bool)\n",
    "y = np.zeros((len(seqs), len(chars)), dtype=np.bool)\n",
    "\n",
    "# fill the right elements of the vectors\n",
    "for i, seq in enumerate(seqs):\n",
    "    for t, c in enumerate(seq):\n",
    "        X[i, t, char_indices[c]] = 1\n",
    "    y[i, char_indices[char[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training a language model on about a dozen CPU cores took a weekend.\n",
    "# Instead of starting training yourself, the following pre-trained model files are available.\n",
    "# - trump_epoch_X.h5        where X in [1, 5, 10, 20, 30, 40, 50, 60]\n",
    "# - shakespeare_epoch_X.h5  where X in [1, 5, 10, 14]\n",
    "#   (training for Shakespeare was killed at 14 epochs when Rowan suggested Trump...)\n",
    "# I suggest loading one model at a time and playing with the output. Start with a low number of epochs.\n",
    "# The generated text should get more realistic as the number of epochs increases.\n",
    "\n",
    "model = load_model('models/shakespeare_epoch_1.h5')\n",
    "\n",
    "# If you swap between models (Trump -> Shakespeare),\n",
    "# you need to swap the data and rerun the previous few cells too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is just a helper to sample from the output array of characters in each case.\n",
    "# If we always choose the most likely next character, we get into loops, so instead,\n",
    "# we sample randomly, with a probability assigned by the output of the network.\n",
    "\n",
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    # thieved from Keras creator @fchollet\n",
    "    preds = np.asarray([max(x,10**-10) for x in preds]).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We're going to Make America Great Again \n",
      "of kings, That where did do the world know'st thought in the crown, that I lead the busty \n",
      "I great houre and detend, then the commander of the son of noble did non, the blord of that I part the hand are \n",
      "O, past was for the settle find honour in mare thee and the stand of The king \n",
      "When the farewalp the dingst of the kenther and not may mean, and in the counter \n",
      "What is you the couds, That wherefo"
     ]
    }
   ],
   "source": [
    "# Here's the fun part.\n",
    "# Exercise. Person with the funniest output wins.\n",
    "\n",
    "# Initialisation\n",
    "generated = ''\n",
    "\n",
    "# The seed of the text generation. Feel free to change this,\n",
    "# but make sure it's at least 40 characters:\n",
    "sentence = \"We're going to Make America Great Again \"\n",
    "\n",
    "# Number of characters to generate following the seed.\n",
    "# Try a whole essay!\n",
    "length = 400\n",
    "\n",
    "# The \"temperature\" determines how diverse the generated text is.\n",
    "# It just reweights the output probabilities from the network.\n",
    "# A lower temperature will be more conservative,\n",
    "# whereas a higher temperature will be more diverse,\n",
    "# but probably stop making sense.\n",
    "temperature = 0.7\n",
    "\n",
    "# Below here is boilerplate to output the generated text.\n",
    "sentence = sentence[-40:] # take only the last 40 characters to begin generation.\n",
    "generated += sentence\n",
    "\n",
    "print()\n",
    "sys.stdout.write(generated)\n",
    "print()\n",
    "prev_char = ''\n",
    "for i in range(length):\n",
    "    x = np.zeros((1, seqlen, len(chars)))\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_index = sample(preds, temperature)\n",
    "    next_char = indices_char[next_index]\n",
    "    \n",
    "    generated += next_char\n",
    "    sentence = sentence[1:] + next_char\n",
    "    \n",
    "    # This is because I did not preprocess the text optimally,\n",
    "    # so it doesn't know about full stops. Alas now it sometimes\n",
    "    # spits out strings of newlines.\n",
    "    if prev_char == ' ' and next_char == ' ':\n",
    "        sys.stdout.write('\\n')\n",
    "    else:\n",
    "        sys.stdout.write(next_char)\n",
    "    prev_char = next_char\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congrats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I hope you learned something. I was blown away the first time I saw how good language generation at the  _character_ level could be. I leave some links for further reading below. Any follow up questions, I can be contacted on twitter [@bitcollider_io](https://twitter.com/bitcollider_io), or drop me a mail at\n",
    "\n",
    "`<my first name (5 characters)>@bitcollider.io`\n",
    "\n",
    "(Gotta avoid those spammers scraping GitHub)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting started:\n",
    "- [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/)\n",
    "- [Hacker's Guide to Neural Networks](http://karpathy.github.io/neuralnets/)\n",
    "\n",
    "Further reading on RNNs:\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "- [Deep Learning, NLP, and Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)\n",
    "- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- [WildML RNN tutorial](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/)\n",
    "    \n",
    "Libraries\n",
    "- [TensorFlow](https://www.tensorflow.org/)\n",
    "- [Keras](https://keras.io/)\n",
    "- [PyTorch](http://pytorch.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
